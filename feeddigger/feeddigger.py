import opml
import feedparser
import boto
import simplejson
from datetime import datetime, date, time, timedelta
from xml.etree.ElementTree import Element, SubElement, Comment
from xml.dom import minidom
from xml.etree import ElementTree
import logging
import os
from boto.s3.connection import S3Connection
from boto.s3.key import Key

AWS_ACCESS_KEY_ID = "NOTHING"
AWS_SECRET_ACCESS_KEY = "NOTHING"

def putCloud(type, name):
	c = S3Connection(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
	b = c.create_bucket('alpha.socialgrep.com')
	k = Key(b)
	k.key=type+'/'+name
	k.set_contents_from_filename(name)
	k.key=type+'/'+"latest.opml"
	k.set_contents_from_filename(name)
	return

def prettify(element):
	rough_string = ElementTree.tostring(element, 'utf-8')
	reparsed = minidom.parseString(rough_string)
	return reparsed.toprettyxml(indent="  ")

def genStringID():
	"""docstring for genStringID"""
	return (datetime.utcnow()).strftime('%Y%m%d%H%M')

def genSnapshot():
	"""docstring for genSnapshot"""
	stringID = genStringID()
	generated_on = datetime.utcnow()
	
	logger = logging.getLogger("["+stringID+"]")
	logger.setLevel(logging.INFO)
	
	root = Element('opml')
	root.set('version','1.0')
	
	root.append(Comment('Generated by FeedDigger'))
	
	head = SubElement(root, 'head')
	title = SubElement(head, 'title')
	title.text = 'grep last 5 minutes '+stringID
	dc = SubElement(head, 'dateCreated')
	dc.text = str(generated_on)
	dm = SubElement(head,'dateModified')
	dm.text = str(generated_on)
	
	body = SubElement(root, 'body')
	
	previous_sources = opml.parse('http://www.techmeme.com/lb.opml')
	logger.info("Starting "+str(generated_on))
	for each in previous_sources:
		try:
			d = feedparser.parse(each.xmlUrl)
			try:
				logger.info("Parsing "+d.feed.title)
				#if datetime.utcfromtimestamp(d.updated_parsed) > (generated_on-timedelta(days = 1)):
				#	print str(datetime(*entry.updated_parsed[:6])), str((generated_on-timedelta(days = 1)))
				for entry in d.entries:
					if (datetime(*entry.updated_parsed[:6]) > (generated_on-timedelta(minutes = 5))) and (datetime(*entry.updated_parsed[:6]) < (generated_on)):
						logger.info("Found "+entry.title+" at "+d.feed.title)
						entry = SubElement(body, 'outline', {'title':entry.title, 'link':entry.link, 'author':entry.author, 'feed_title':d.feed.title, 'updated_at':str(datetime(*entry.updated_parsed[:6]))})
			except TypeError:
				pass
		except UnicodeEncodeError:
			pass
		except AttributeError:
			pass

	f = open(stringID+".opml",'w')
	f.write((prettify(root)).encode('utf-8'))
	f.close()
	#putCloud("river",stringID+".opml")
	#os.remove(stringID+".opml")
	logger.info("Ended "+str(datetime.utcnow()))

if __name__ == "__main__":
	LOG_FILENAME_INFO = 'feeddigger_info.log'
	logging.basicConfig(filename=LOG_FILENAME_INFO, level=logging.INFO)
	genSnapshot()
